{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "37026afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "47279f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.read_csv('features.csv')\n",
    "df_feat['GAME_DATE'] = pd.to_datetime(df_feat['GAME_DATE'])\n",
    "df_feat = df_feat.set_index(['GAME_DATE', 'GAME_ID', 'TEAM_ABBREVIATION'])\n",
    "df_feat = df_feat.sort_index(level=['TEAM_ABBREVIATION', 'GAME_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "74ed958d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Win</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3_PCT</th>\n",
       "      <th>FT_PCT</th>\n",
       "      <th>FGM_per48</th>\n",
       "      <th>FGA_per48</th>\n",
       "      <th>FG3M_per48</th>\n",
       "      <th>FG3A_per48</th>\n",
       "      <th>FTM_per48</th>\n",
       "      <th>...</th>\n",
       "      <th>FGM_per48_against_z_prev</th>\n",
       "      <th>FGA_per48_against_z_opp</th>\n",
       "      <th>FGA_per48_against_z_prev</th>\n",
       "      <th>FG3M_per48_against_z_opp</th>\n",
       "      <th>FG3M_per48_against_z_prev</th>\n",
       "      <th>FG3A_per48_against_z_opp</th>\n",
       "      <th>FG3A_per48_against_z_prev</th>\n",
       "      <th>FTM_per48_against_z_opp</th>\n",
       "      <th>FTM_per48_against_z_prev</th>\n",
       "      <th>FTA_per48_against_z_opp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-10-29</th>\n",
       "      <th>21400008</th>\n",
       "      <td>0.582294</td>\n",
       "      <td>36.555960</td>\n",
       "      <td>0.449012</td>\n",
       "      <td>0.370809</td>\n",
       "      <td>0.785540</td>\n",
       "      <td>36.093331</td>\n",
       "      <td>80.645887</td>\n",
       "      <td>8.578857</td>\n",
       "      <td>22.881644</td>\n",
       "      <td>19.265863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705149</td>\n",
       "      <td>0.173537</td>\n",
       "      <td>-1.213736</td>\n",
       "      <td>0.550920</td>\n",
       "      <td>-0.633959</td>\n",
       "      <td>0.543197</td>\n",
       "      <td>-1.179740</td>\n",
       "      <td>-0.658100</td>\n",
       "      <td>0.719120</td>\n",
       "      <td>-0.567656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-07</th>\n",
       "      <th>21400077</th>\n",
       "      <td>0.604650</td>\n",
       "      <td>36.523515</td>\n",
       "      <td>0.447226</td>\n",
       "      <td>0.362539</td>\n",
       "      <td>0.784985</td>\n",
       "      <td>36.108373</td>\n",
       "      <td>80.986769</td>\n",
       "      <td>8.335616</td>\n",
       "      <td>22.786700</td>\n",
       "      <td>20.068602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.596801</td>\n",
       "      <td>-0.935076</td>\n",
       "      <td>-1.203649</td>\n",
       "      <td>-0.344142</td>\n",
       "      <td>-0.532947</td>\n",
       "      <td>0.044288</td>\n",
       "      <td>-1.083389</td>\n",
       "      <td>-0.032128</td>\n",
       "      <td>0.540420</td>\n",
       "      <td>-0.251170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-13</th>\n",
       "      <th>21400119</th>\n",
       "      <td>0.629524</td>\n",
       "      <td>36.595412</td>\n",
       "      <td>0.449694</td>\n",
       "      <td>0.365954</td>\n",
       "      <td>0.788200</td>\n",
       "      <td>36.206388</td>\n",
       "      <td>80.776526</td>\n",
       "      <td>8.335478</td>\n",
       "      <td>22.610932</td>\n",
       "      <td>20.400285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511760</td>\n",
       "      <td>-0.456520</td>\n",
       "      <td>-1.239463</td>\n",
       "      <td>-1.945282</td>\n",
       "      <td>-0.403724</td>\n",
       "      <td>-1.777764</td>\n",
       "      <td>-0.956587</td>\n",
       "      <td>-1.245822</td>\n",
       "      <td>0.553171</td>\n",
       "      <td>-1.227617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-26</th>\n",
       "      <th>21400215</th>\n",
       "      <td>0.655447</td>\n",
       "      <td>36.803552</td>\n",
       "      <td>0.450485</td>\n",
       "      <td>0.366271</td>\n",
       "      <td>0.790026</td>\n",
       "      <td>36.461941</td>\n",
       "      <td>81.159754</td>\n",
       "      <td>8.372597</td>\n",
       "      <td>22.651187</td>\n",
       "      <td>20.501178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.840741</td>\n",
       "      <td>0.207250</td>\n",
       "      <td>-1.180405</td>\n",
       "      <td>0.462740</td>\n",
       "      <td>-0.752348</td>\n",
       "      <td>0.488385</td>\n",
       "      <td>-1.227546</td>\n",
       "      <td>-0.719413</td>\n",
       "      <td>0.805615</td>\n",
       "      <td>-0.673349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-14</th>\n",
       "      <th>21400353</th>\n",
       "      <td>0.638197</td>\n",
       "      <td>37.557371</td>\n",
       "      <td>0.454826</td>\n",
       "      <td>0.369389</td>\n",
       "      <td>0.796096</td>\n",
       "      <td>37.117018</td>\n",
       "      <td>81.855921</td>\n",
       "      <td>8.670072</td>\n",
       "      <td>23.338218</td>\n",
       "      <td>20.054915</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562499</td>\n",
       "      <td>-1.560270</td>\n",
       "      <td>-1.226973</td>\n",
       "      <td>1.205827</td>\n",
       "      <td>-0.537212</td>\n",
       "      <td>0.981219</td>\n",
       "      <td>-1.041927</td>\n",
       "      <td>0.705019</td>\n",
       "      <td>0.614039</td>\n",
       "      <td>0.709729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <th>22300492</th>\n",
       "      <td>0.470899</td>\n",
       "      <td>42.685754</td>\n",
       "      <td>0.470877</td>\n",
       "      <td>0.345882</td>\n",
       "      <td>0.763804</td>\n",
       "      <td>42.481832</td>\n",
       "      <td>90.370527</td>\n",
       "      <td>11.180462</td>\n",
       "      <td>32.315327</td>\n",
       "      <td>17.157224</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.586697</td>\n",
       "      <td>-0.142994</td>\n",
       "      <td>-1.608489</td>\n",
       "      <td>0.596810</td>\n",
       "      <td>0.721406</td>\n",
       "      <td>-0.269284</td>\n",
       "      <td>0.820980</td>\n",
       "      <td>0.135694</td>\n",
       "      <td>0.704565</td>\n",
       "      <td>-0.046906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <th>22300504</th>\n",
       "      <td>0.460808</td>\n",
       "      <td>42.778199</td>\n",
       "      <td>0.472358</td>\n",
       "      <td>0.345992</td>\n",
       "      <td>0.765694</td>\n",
       "      <td>42.578647</td>\n",
       "      <td>90.298304</td>\n",
       "      <td>11.219451</td>\n",
       "      <td>32.415710</td>\n",
       "      <td>17.282423</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.473575</td>\n",
       "      <td>0.577864</td>\n",
       "      <td>-1.665435</td>\n",
       "      <td>0.230662</td>\n",
       "      <td>0.749217</td>\n",
       "      <td>0.622859</td>\n",
       "      <td>0.755369</td>\n",
       "      <td>0.888429</td>\n",
       "      <td>0.799060</td>\n",
       "      <td>0.920233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <th>22300516</th>\n",
       "      <td>0.472362</td>\n",
       "      <td>43.040087</td>\n",
       "      <td>0.474772</td>\n",
       "      <td>0.348328</td>\n",
       "      <td>0.761522</td>\n",
       "      <td>42.844811</td>\n",
       "      <td>90.377624</td>\n",
       "      <td>11.300461</td>\n",
       "      <td>32.428230</td>\n",
       "      <td>17.083519</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.268621</td>\n",
       "      <td>1.349238</td>\n",
       "      <td>-1.827138</td>\n",
       "      <td>1.629375</td>\n",
       "      <td>0.386913</td>\n",
       "      <td>1.368564</td>\n",
       "      <td>0.302253</td>\n",
       "      <td>-1.771477</td>\n",
       "      <td>0.658658</td>\n",
       "      <td>-1.865103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <th>22300526</th>\n",
       "      <td>0.462240</td>\n",
       "      <td>43.253508</td>\n",
       "      <td>0.476684</td>\n",
       "      <td>0.351278</td>\n",
       "      <td>0.758382</td>\n",
       "      <td>43.062415</td>\n",
       "      <td>90.455244</td>\n",
       "      <td>11.422590</td>\n",
       "      <td>32.483338</td>\n",
       "      <td>16.888878</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.332744</td>\n",
       "      <td>-0.048127</td>\n",
       "      <td>-1.865877</td>\n",
       "      <td>-0.142924</td>\n",
       "      <td>0.549692</td>\n",
       "      <td>-0.153797</td>\n",
       "      <td>0.333484</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.876584</td>\n",
       "      <td>-0.336221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <th>22300540</th>\n",
       "      <td>0.452335</td>\n",
       "      <td>43.312359</td>\n",
       "      <td>0.478212</td>\n",
       "      <td>0.352322</td>\n",
       "      <td>0.761181</td>\n",
       "      <td>43.125362</td>\n",
       "      <td>90.316921</td>\n",
       "      <td>11.434963</td>\n",
       "      <td>32.430125</td>\n",
       "      <td>16.869832</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.098912</td>\n",
       "      <td>1.258300</td>\n",
       "      <td>-1.702580</td>\n",
       "      <td>1.688280</td>\n",
       "      <td>0.644485</td>\n",
       "      <td>1.328092</td>\n",
       "      <td>0.193153</td>\n",
       "      <td>-0.465659</td>\n",
       "      <td>0.477886</td>\n",
       "      <td>-0.347466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>682 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Win        FGM    FG_PCT   FG3_PCT    FT_PCT  \\\n",
       "GAME_DATE  GAME_ID                                                       \n",
       "2014-10-29 21400008  0.582294  36.555960  0.449012  0.370809  0.785540   \n",
       "2014-11-07 21400077  0.604650  36.523515  0.447226  0.362539  0.784985   \n",
       "2014-11-13 21400119  0.629524  36.595412  0.449694  0.365954  0.788200   \n",
       "2014-11-26 21400215  0.655447  36.803552  0.450485  0.366271  0.790026   \n",
       "2014-12-14 21400353  0.638197  37.557371  0.454826  0.369389  0.796096   \n",
       "...                       ...        ...       ...       ...       ...   \n",
       "2024-01-05 22300492  0.470899  42.685754  0.470877  0.345882  0.763804   \n",
       "2024-01-07 22300504  0.460808  42.778199  0.472358  0.345992  0.765694   \n",
       "2024-01-09 22300516  0.472362  43.040087  0.474772  0.348328  0.761522   \n",
       "2024-01-10 22300526  0.462240  43.253508  0.476684  0.351278  0.758382   \n",
       "2024-01-12 22300540  0.452335  43.312359  0.478212  0.352322  0.761181   \n",
       "\n",
       "                     FGM_per48  FGA_per48  FG3M_per48  FG3A_per48  FTM_per48  \\\n",
       "GAME_DATE  GAME_ID                                                             \n",
       "2014-10-29 21400008  36.093331  80.645887    8.578857   22.881644  19.265863   \n",
       "2014-11-07 21400077  36.108373  80.986769    8.335616   22.786700  20.068602   \n",
       "2014-11-13 21400119  36.206388  80.776526    8.335478   22.610932  20.400285   \n",
       "2014-11-26 21400215  36.461941  81.159754    8.372597   22.651187  20.501178   \n",
       "2014-12-14 21400353  37.117018  81.855921    8.670072   23.338218  20.054915   \n",
       "...                        ...        ...         ...         ...        ...   \n",
       "2024-01-05 22300492  42.481832  90.370527   11.180462   32.315327  17.157224   \n",
       "2024-01-07 22300504  42.578647  90.298304   11.219451   32.415710  17.282423   \n",
       "2024-01-09 22300516  42.844811  90.377624   11.300461   32.428230  17.083519   \n",
       "2024-01-10 22300526  43.062415  90.455244   11.422590   32.483338  16.888878   \n",
       "2024-01-12 22300540  43.125362  90.316921   11.434963   32.430125  16.869832   \n",
       "\n",
       "                     ...  FGM_per48_against_z_prev  FGA_per48_against_z_opp  \\\n",
       "GAME_DATE  GAME_ID   ...                                                      \n",
       "2014-10-29 21400008  ...                 -0.705149                 0.173537   \n",
       "2014-11-07 21400077  ...                 -0.596801                -0.935076   \n",
       "2014-11-13 21400119  ...                 -0.511760                -0.456520   \n",
       "2014-11-26 21400215  ...                 -0.840741                 0.207250   \n",
       "2014-12-14 21400353  ...                 -0.562499                -1.560270   \n",
       "...                  ...                       ...                      ...   \n",
       "2024-01-05 22300492  ...                 -1.586697                -0.142994   \n",
       "2024-01-07 22300504  ...                 -1.473575                 0.577864   \n",
       "2024-01-09 22300516  ...                 -1.268621                 1.349238   \n",
       "2024-01-10 22300526  ...                 -1.332744                -0.048127   \n",
       "2024-01-12 22300540  ...                 -1.098912                 1.258300   \n",
       "\n",
       "                     FGA_per48_against_z_prev  FG3M_per48_against_z_opp  \\\n",
       "GAME_DATE  GAME_ID                                                        \n",
       "2014-10-29 21400008                 -1.213736                  0.550920   \n",
       "2014-11-07 21400077                 -1.203649                 -0.344142   \n",
       "2014-11-13 21400119                 -1.239463                 -1.945282   \n",
       "2014-11-26 21400215                 -1.180405                  0.462740   \n",
       "2014-12-14 21400353                 -1.226973                  1.205827   \n",
       "...                                       ...                       ...   \n",
       "2024-01-05 22300492                 -1.608489                  0.596810   \n",
       "2024-01-07 22300504                 -1.665435                  0.230662   \n",
       "2024-01-09 22300516                 -1.827138                  1.629375   \n",
       "2024-01-10 22300526                 -1.865877                 -0.142924   \n",
       "2024-01-12 22300540                 -1.702580                  1.688280   \n",
       "\n",
       "                     FG3M_per48_against_z_prev  FG3A_per48_against_z_opp  \\\n",
       "GAME_DATE  GAME_ID                                                         \n",
       "2014-10-29 21400008                  -0.633959                  0.543197   \n",
       "2014-11-07 21400077                  -0.532947                  0.044288   \n",
       "2014-11-13 21400119                  -0.403724                 -1.777764   \n",
       "2014-11-26 21400215                  -0.752348                  0.488385   \n",
       "2014-12-14 21400353                  -0.537212                  0.981219   \n",
       "...                                        ...                       ...   \n",
       "2024-01-05 22300492                   0.721406                 -0.269284   \n",
       "2024-01-07 22300504                   0.749217                  0.622859   \n",
       "2024-01-09 22300516                   0.386913                  1.368564   \n",
       "2024-01-10 22300526                   0.549692                 -0.153797   \n",
       "2024-01-12 22300540                   0.644485                  1.328092   \n",
       "\n",
       "                     FG3A_per48_against_z_prev  FTM_per48_against_z_opp  \\\n",
       "GAME_DATE  GAME_ID                                                        \n",
       "2014-10-29 21400008                  -1.179740                -0.658100   \n",
       "2014-11-07 21400077                  -1.083389                -0.032128   \n",
       "2014-11-13 21400119                  -0.956587                -1.245822   \n",
       "2014-11-26 21400215                  -1.227546                -0.719413   \n",
       "2014-12-14 21400353                  -1.041927                 0.705019   \n",
       "...                                        ...                      ...   \n",
       "2024-01-05 22300492                   0.820980                 0.135694   \n",
       "2024-01-07 22300504                   0.755369                 0.888429   \n",
       "2024-01-09 22300516                   0.302253                -1.771477   \n",
       "2024-01-10 22300526                   0.333484                -0.302188   \n",
       "2024-01-12 22300540                   0.193153                -0.465659   \n",
       "\n",
       "                     FTM_per48_against_z_prev  FTA_per48_against_z_opp  \n",
       "GAME_DATE  GAME_ID                                                      \n",
       "2014-10-29 21400008                  0.719120                -0.567656  \n",
       "2014-11-07 21400077                  0.540420                -0.251170  \n",
       "2014-11-13 21400119                  0.553171                -1.227617  \n",
       "2014-11-26 21400215                  0.805615                -0.673349  \n",
       "2014-12-14 21400353                  0.614039                 0.709729  \n",
       "...                                       ...                      ...  \n",
       "2024-01-05 22300492                  0.704565                -0.046906  \n",
       "2024-01-07 22300504                  0.799060                 0.920233  \n",
       "2024-01-09 22300516                  0.658658                -1.865103  \n",
       "2024-01-10 22300526                  0.876584                -0.336221  \n",
       "2024-01-12 22300540                  0.477886                -0.347466  \n",
       "\n",
       "[682 rows x 201 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat.loc[:,:,'TOR']#[['OffRat', 'DefRat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "76f86431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'AST%',\n",
      "'AST%_opp',\n",
      "'AST%_z',\n",
      "'AST%_z_opp',\n",
      "'AST_per48',\n",
      "'AST_per48_against',\n",
      "'AST_per48_against_opp',\n",
      "'AST_per48_opp',\n",
      "'BB%',\n",
      "'BLKA_per48',\n",
      "'BLKA_per48_against',\n",
      "'BLKA_per48_against_opp',\n",
      "'BLKA_per48_opp',\n",
      "'BLK_per48',\n",
      "'BLK_per48_against',\n",
      "'BLK_per48_against_opp',\n",
      "'BLK_per48_opp',\n",
      "'DER',\n",
      "'DREB%',\n",
      "'DREB%_opp',\n",
      "'DREB%_z',\n",
      "'DREB%_z_opp',\n",
      "'DREB%_z_prev',\n",
      "'DREB_per48',\n",
      "'DREB_per48_against',\n",
      "'DREB_per48_against_opp',\n",
      "'DREB_per48_opp',\n",
      "'DREB_per48_prev',\n",
      "'DREB_per48_z',\n",
      "'DREB_per48_z_opp',\n",
      "'DaysElapsed',\n",
      "'DaysRest',\n",
      "'DaysRest_opp',\n",
      "'DefRat',\n",
      "'DefRat_opp',\n",
      "'DefRat_prev',\n",
      "'DefRat_z',\n",
      "'DefRat_z_opp',\n",
      "'DefRat_z_prev',\n",
      "'FG3A_per48',\n",
      "'FG3A_per48_against',\n",
      "'FG3A_per48_against_opp',\n",
      "'FG3A_per48_against_z',\n",
      "'FG3A_per48_against_z_opp',\n",
      "'FG3A_per48_against_z_prev',\n",
      "'FG3A_per48_opp',\n",
      "'FG3A_per48_prev',\n",
      "'FG3A_per48_z',\n",
      "'FG3A_per48_z_opp',\n",
      "'FG3A_per48_z_prev',\n",
      "'FG3M_per48',\n",
      "'FG3M_per48_against',\n",
      "'FG3M_per48_against_opp',\n",
      "'FG3M_per48_against_z',\n",
      "'FG3M_per48_against_z_opp',\n",
      "'FG3M_per48_against_z_prev',\n",
      "'FG3M_per48_opp',\n",
      "'FG3M_per48_z',\n",
      "'FG3M_per48_z_opp',\n",
      "'FG3M_per48_z_prev',\n",
      "'FG3_PCT',\n",
      "'FG3_PCT_against',\n",
      "'FG3_PCT_against_opp',\n",
      "'FG3_PCT_opp',\n",
      "'FGA_per48',\n",
      "'FGA_per48_against',\n",
      "'FGA_per48_against_opp',\n",
      "'FGA_per48_against_z',\n",
      "'FGA_per48_against_z_opp',\n",
      "'FGA_per48_against_z_prev',\n",
      "'FGA_per48_opp',\n",
      "'FGA_per48_prev',\n",
      "'FGA_per48_z',\n",
      "'FGA_per48_z_opp',\n",
      "'FGA_per48_z_prev',\n",
      "'FGM',\n",
      "'FGM_per48',\n",
      "'FGM_per48_against',\n",
      "'FGM_per48_against_opp',\n",
      "'FGM_per48_against_z',\n",
      "'FGM_per48_against_z_opp',\n",
      "'FGM_per48_against_z_prev',\n",
      "'FGM_per48_opp',\n",
      "'FGM_per48_z',\n",
      "'FGM_per48_z_opp',\n",
      "'FGM_per48_z_prev',\n",
      "'FG_PCT',\n",
      "'FG_PCT_against',\n",
      "'FG_PCT_against_opp',\n",
      "'FG_PCT_opp',\n",
      "'FTA_per48',\n",
      "'FTA_per48_against',\n",
      "'FTA_per48_against_opp',\n",
      "'FTA_per48_against_prev',\n",
      "'FTA_per48_against_z',\n",
      "'FTA_per48_against_z_opp',\n",
      "'FTA_per48_opp',\n",
      "'FTA_per48_prev',\n",
      "'FTA_per48_z',\n",
      "'FTA_per48_z_opp',\n",
      "'FTA_per48_z_prev',\n",
      "'FTM_per48',\n",
      "'FTM_per48_against',\n",
      "'FTM_per48_against_opp',\n",
      "'FTM_per48_against_z',\n",
      "'FTM_per48_against_z_opp',\n",
      "'FTM_per48_against_z_prev',\n",
      "'FTM_per48_opp',\n",
      "'FTM_per48_z',\n",
      "'FTM_per48_z_opp',\n",
      "'FTM_per48_z_prev',\n",
      "'FT_PCT',\n",
      "'FT_PCT_opp',\n",
      "'Home',\n",
      "'MATCHUP',\n",
      "'OER',\n",
      "'OREB%',\n",
      "'OREB%_opp',\n",
      "'OREB%_z',\n",
      "'OREB%_z_opp',\n",
      "'OREB%_z_prev',\n",
      "'OREB_per48',\n",
      "'OREB_per48_against',\n",
      "'OREB_per48_against_opp',\n",
      "'OREB_per48_opp',\n",
      "'OREB_per48_prev',\n",
      "'OREB_per48_z',\n",
      "'OREB_per48_z_opp',\n",
      "'OffRat',\n",
      "'OffRat_opp',\n",
      "'OffRat_prev',\n",
      "'OffRat_z',\n",
      "'OffRat_z_opp',\n",
      "'OffRat_z_prev',\n",
      "'PFD_per48',\n",
      "'PFD_per48_against',\n",
      "'PFD_per48_against_opp',\n",
      "'PFD_per48_opp',\n",
      "'PF_per48',\n",
      "'PF_per48_against',\n",
      "'PF_per48_against_opp',\n",
      "'PF_per48_opp',\n",
      "'PLUS_MINUS_per48',\n",
      "'PLUS_MINUS_per48_opp',\n",
      "'PTS_per48',\n",
      "'PTS_per48_against',\n",
      "'PTS_per48_against_opp',\n",
      "'PTS_per48_against_z',\n",
      "'PTS_per48_against_z_opp',\n",
      "'PTS_per48_against_z_prev',\n",
      "'PTS_per48_opp',\n",
      "'PTS_per48_z',\n",
      "'PTS_per48_z_opp',\n",
      "'PTS_per48_z_prev',\n",
      "'Poss',\n",
      "'Poss_opp',\n",
      "'REB_per48',\n",
      "'REB_per48_against',\n",
      "'REB_per48_against_opp',\n",
      "'REB_per48_opp',\n",
      "'REB_per48_prev',\n",
      "'STL%',\n",
      "'STL%_opp',\n",
      "'STL%_z',\n",
      "'STL%_z_opp',\n",
      "'STL_per48',\n",
      "'STL_per48_against',\n",
      "'STL_per48_against_opp',\n",
      "'STL_per48_opp',\n",
      "'TOV%',\n",
      "'TOV%_opp',\n",
      "'TOV%_z',\n",
      "'TOV%_z_opp',\n",
      "'TOV_forced%',\n",
      "'TOV_forced%_opp',\n",
      "'TOV_forced%_z',\n",
      "'TOV_forced%_z_opp',\n",
      "'TOV_per48',\n",
      "'TOV_per48_against',\n",
      "'TOV_per48_against_opp',\n",
      "'TOV_per48_opp',\n",
      "'TS%',\n",
      "'TS%_against',\n",
      "'TS%_against_opp',\n",
      "'TS%_against_z',\n",
      "'TS%_against_z_opp',\n",
      "'TS%_opp',\n",
      "'WL',\n",
      "'Win',\n",
      "'Win_against',\n",
      "'Win_opp',\n",
      "'eFG%',\n",
      "'eFG%_against',\n",
      "'eFG%_against_opp',\n",
      "'eFG%_against_z',\n",
      "'eFG%_against_z_opp',\n",
      "'eFG%_opp',\n",
      "'eFG%_z',\n",
      "'eFG%_z_opp',\n",
      "'roadtrip',\n",
      "'roadtrip_opp',\n"
     ]
    }
   ],
   "source": [
    "column_names = sorted(df_feat.columns)\n",
    "for col in column_names:\n",
    "    print(\"\\'{}\\',\".format(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122b01d8",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2f351",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d1e368cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "_against : stats against a team (what does a team give up per game?)\n",
    "_opp : stats of the opposing team in a matchup (how does the opposing team perform?)\n",
    "_against_opp : stats against of the opposing team (what does the opposing team give up per game?)\n",
    "_prev5 : stats from previous 5 games of a team matchup\n",
    "\n",
    "'''\n",
    "\n",
    "feature_cols = [#'PTS_per48_z',\n",
    "#                 'PTS_per48_z_opp',\n",
    "#                 'BLKA_per48',\n",
    "#                 'BLKA_per48_opp',\n",
    "                'DaysRest',\n",
    "                'DaysRest_opp',\n",
    "                'DefRat_z',\n",
    "                'DefRat_z_prev',\n",
    "                'DefRat_z_opp',\n",
    "#                 'DREB%_opp',\n",
    "#                 'DREB%',\n",
    "                'Home',\n",
    "                'OffRat_z',\n",
    "                'OffRat_z_prev',\n",
    "                'OffRat_z_opp',\n",
    "                'OREB%_opp',\n",
    "                'OREB%',\n",
    "#                 'TOV%_opp',\n",
    "#                 'TOV%',\n",
    "                'Win',\n",
    "                'Win_opp',\n",
    "#                 'eFG%',\n",
    "#                 'eFG%_opp',\n",
    "                'roadtrip',\n",
    "                'roadtrip_opp',\n",
    "#                 'BB%'\n",
    "    ]\n",
    "\n",
    "\n",
    "X = df_feat[feature_cols]\n",
    "y = df_feat['WL']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)#, random_state=100)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f22f6076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DaysRest</td>\n",
       "      <td>8.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DaysRest_opp</td>\n",
       "      <td>8.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DefRat_z</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DefRat_z_prev</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DefRat_z_opp</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Home</td>\n",
       "      <td>7.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OffRat_z</td>\n",
       "      <td>5.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OffRat_z_prev</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OffRat_z_opp</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OREB%_opp</td>\n",
       "      <td>111.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OREB%</td>\n",
       "      <td>113.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Win</td>\n",
       "      <td>129.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Win_opp</td>\n",
       "      <td>126.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>roadtrip</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>roadtrip_opp</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature     VIF\n",
       "0        DaysRest    8.36\n",
       "1    DaysRest_opp    8.35\n",
       "2        DefRat_z    4.22\n",
       "3   DefRat_z_prev    1.98\n",
       "4    DefRat_z_opp    3.42\n",
       "5            Home    7.13\n",
       "6        OffRat_z    5.44\n",
       "7   OffRat_z_prev    2.04\n",
       "8    OffRat_z_opp    4.98\n",
       "9       OREB%_opp  111.83\n",
       "10          OREB%  113.66\n",
       "11            Win  129.10\n",
       "12        Win_opp  126.67\n",
       "13       roadtrip    3.56\n",
       "14   roadtrip_opp    3.59"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = np.round([variance_inflation_factor(X.values, i) for i in range(X.shape[1])],2)\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "885af94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.622688\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>WL</td>        <th>  No. Observations:  </th>  <td> 16295</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 16280</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 14 Jan 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.1016</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>17:19:52</td>     <th>  Log-Likelihood:    </th> <td> -10147.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -11295.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>    0.1100</td> <td>    0.018</td> <td>    6.069</td> <td> 0.000</td> <td>    0.074</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>   -0.0985</td> <td>    0.018</td> <td>   -5.446</td> <td> 0.000</td> <td>   -0.134</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>   -0.2138</td> <td>    0.039</td> <td>   -5.460</td> <td> 0.000</td> <td>   -0.291</td> <td>   -0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>    0.0598</td> <td>    0.024</td> <td>    2.527</td> <td> 0.012</td> <td>    0.013</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>    0.1443</td> <td>    0.036</td> <td>    4.035</td> <td> 0.000</td> <td>    0.074</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>    0.3348</td> <td>    0.032</td> <td>   10.461</td> <td> 0.000</td> <td>    0.272</td> <td>    0.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>    0.3005</td> <td>    0.046</td> <td>    6.571</td> <td> 0.000</td> <td>    0.211</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>   -0.0845</td> <td>    0.024</td> <td>   -3.516</td> <td> 0.000</td> <td>   -0.132</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>   -0.2145</td> <td>    0.045</td> <td>   -4.805</td> <td> 0.000</td> <td>   -0.302</td> <td>   -0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>   -0.0081</td> <td>    0.017</td> <td>   -0.470</td> <td> 0.639</td> <td>   -0.042</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>   -0.0129</td> <td>    0.017</td> <td>   -0.751</td> <td> 0.453</td> <td>   -0.047</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>    0.2147</td> <td>    0.060</td> <td>    3.554</td> <td> 0.000</td> <td>    0.096</td> <td>    0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>   -0.2363</td> <td>    0.060</td> <td>   -3.957</td> <td> 0.000</td> <td>   -0.353</td> <td>   -0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th> <td>    0.0148</td> <td>    0.026</td> <td>    0.578</td> <td> 0.563</td> <td>   -0.035</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th> <td>   -0.0224</td> <td>    0.026</td> <td>   -0.879</td> <td> 0.379</td> <td>   -0.073</td> <td>    0.028</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &        WL        & \\textbf{  No. Observations:  } &    16295    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &    16280    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &       14    \\\\\n",
       "\\textbf{Date:}            & Sun, 14 Jan 2024 & \\textbf{  Pseudo R-squ.:     } &   0.1016    \\\\\n",
       "\\textbf{Time:}            &     17:19:52     & \\textbf{  Log-Likelihood:    } &   -10147.   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -11295.   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } &    0.000    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "             & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{x1}  &       0.1100  &        0.018     &     6.069  &         0.000        &        0.074    &        0.145     \\\\\n",
       "\\textbf{x2}  &      -0.0985  &        0.018     &    -5.446  &         0.000        &       -0.134    &       -0.063     \\\\\n",
       "\\textbf{x3}  &      -0.2138  &        0.039     &    -5.460  &         0.000        &       -0.291    &       -0.137     \\\\\n",
       "\\textbf{x4}  &       0.0598  &        0.024     &     2.527  &         0.012        &        0.013    &        0.106     \\\\\n",
       "\\textbf{x5}  &       0.1443  &        0.036     &     4.035  &         0.000        &        0.074    &        0.214     \\\\\n",
       "\\textbf{x6}  &       0.3348  &        0.032     &    10.461  &         0.000        &        0.272    &        0.398     \\\\\n",
       "\\textbf{x7}  &       0.3005  &        0.046     &     6.571  &         0.000        &        0.211    &        0.390     \\\\\n",
       "\\textbf{x8}  &      -0.0845  &        0.024     &    -3.516  &         0.000        &       -0.132    &       -0.037     \\\\\n",
       "\\textbf{x9}  &      -0.2145  &        0.045     &    -4.805  &         0.000        &       -0.302    &       -0.127     \\\\\n",
       "\\textbf{x10} &      -0.0081  &        0.017     &    -0.470  &         0.639        &       -0.042    &        0.026     \\\\\n",
       "\\textbf{x11} &      -0.0129  &        0.017     &    -0.751  &         0.453        &       -0.047    &        0.021     \\\\\n",
       "\\textbf{x12} &       0.2147  &        0.060     &     3.554  &         0.000        &        0.096    &        0.333     \\\\\n",
       "\\textbf{x13} &      -0.2363  &        0.060     &    -3.957  &         0.000        &       -0.353    &       -0.119     \\\\\n",
       "\\textbf{x14} &       0.0148  &        0.026     &     0.578  &         0.563        &       -0.035    &        0.065     \\\\\n",
       "\\textbf{x15} &      -0.0224  &        0.026     &    -0.879  &         0.379        &       -0.073    &        0.028     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                     WL   No. Observations:                16295\n",
       "Model:                          Logit   Df Residuals:                    16280\n",
       "Method:                           MLE   Df Model:                           14\n",
       "Date:                Sun, 14 Jan 2024   Pseudo R-squ.:                  0.1016\n",
       "Time:                        17:19:52   Log-Likelihood:                -10147.\n",
       "converged:                       True   LL-Null:                       -11295.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.1100      0.018      6.069      0.000       0.074       0.145\n",
       "x2            -0.0985      0.018     -5.446      0.000      -0.134      -0.063\n",
       "x3            -0.2138      0.039     -5.460      0.000      -0.291      -0.137\n",
       "x4             0.0598      0.024      2.527      0.012       0.013       0.106\n",
       "x5             0.1443      0.036      4.035      0.000       0.074       0.214\n",
       "x6             0.3348      0.032     10.461      0.000       0.272       0.398\n",
       "x7             0.3005      0.046      6.571      0.000       0.211       0.390\n",
       "x8            -0.0845      0.024     -3.516      0.000      -0.132      -0.037\n",
       "x9            -0.2145      0.045     -4.805      0.000      -0.302      -0.127\n",
       "x10           -0.0081      0.017     -0.470      0.639      -0.042       0.026\n",
       "x11           -0.0129      0.017     -0.751      0.453      -0.047       0.021\n",
       "x12            0.2147      0.060      3.554      0.000       0.096       0.333\n",
       "x13           -0.2363      0.060     -3.957      0.000      -0.353      -0.119\n",
       "x14            0.0148      0.026      0.578      0.563      -0.035       0.065\n",
       "x15           -0.0224      0.026     -0.879      0.379      -0.073       0.028\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logit = sm.Logit(y_train, X_train).fit()\n",
    "model_logit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "09e63ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6580756013745704\n",
      "Sensitivity: 0.654048873981792\n",
      "Specificity: 0.6623049823855058\n"
     ]
    }
   ],
   "source": [
    "logit_prob = model_logit.predict(X_test)\n",
    "logit_pred = np.round(logit_prob)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, logit_pred)\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "logit_accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "print(\"Accuracy:\", logit_accuracy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b422523",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a92cbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "_against : stats against a team (what does a team give up per game?)\n",
    "_opp : stats of the opposing team in a matchup (how does the opposing team perform?)\n",
    "_against_opp : stats against of the opposing team (what does the opposing team give up per game?)\n",
    "_prev : stats from previous 6 games of a team matchup\n",
    "\n",
    "'''\n",
    "\n",
    "feature_cols = ['AST%',\n",
    "                'AST%_opp',\n",
    "                'BLKA_per48',\n",
    "                'BLKA_per48_opp',\n",
    "                'DaysRest',\n",
    "                'DaysRest_opp',\n",
    "                'DefRat_z',\n",
    "                'DefRat_z_opp',\n",
    "                'DREB%_opp',\n",
    "                'DREB%',\n",
    "                'FT_PCT',\n",
    "                'FT_PCT_opp',\n",
    "                'Home',\n",
    "                'OffRat_z',\n",
    "                'OffRat_z_opp',\n",
    "                'OREB%_opp',\n",
    "                'OREB%',\n",
    "                'STL%_opp',\n",
    "                'STL%_z',\n",
    "                'TOV%_opp',\n",
    "                'TOV%',\n",
    "                'TOV_forced%_opp',\n",
    "                'TOV_forced%',\n",
    "                'TS%',\n",
    "                'TS%_opp',\n",
    "                'TS%_against',\n",
    "                'TS%_against_opp',\n",
    "                'Win',\n",
    "                'Win_opp',\n",
    "                'eFG%_z',\n",
    "                'eFG%_z_opp',\n",
    "                'eFG%_against',\n",
    "                'eFG%_against_opp',\n",
    "                'roadtrip',\n",
    "                'roadtrip_opp',\n",
    "                'BB%',\n",
    "                'PLUS_MINUS_per48',\n",
    "                'PLUS_MINUS_per48_against',\n",
    "                'PLUS_MINUS_per48_against_opp',\n",
    "                'PLUS_MINUS_per48_opp',\n",
    "                'PTS_per48',\n",
    "                'PTS_per48_against',\n",
    "                'PTS_per48_against_opp',\n",
    "                'PTS_per48_opp',\n",
    "    ]\n",
    "\n",
    "\n",
    "X = df_feat[feature_cols]\n",
    "y = df_feat['WL']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c20c0003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6556210112911144\n",
      "Sensitivity: 0.6482989937709631\n",
      "Specificity: 0.6633115249119276\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = SVC(kernel='linear', C=0.25, random_state=42, probability=True)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "svm_accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "print(\"Accuracy:\", svm_accuracy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n",
    "svm_pred = svm_classifier.predict(X_test)\n",
    "svm_prob = svm_classifier.predict_proba(X_test)[:, 1]  # Probability of class 1 in SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212e7c75",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "80a0d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d9228176",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "_against : stats against a team (what does a team give up per game?)\n",
    "_opp : stats of the opposing team in a matchup (how does the opposing team perform?)\n",
    "_against_opp : stats against of the opposing team (what does the opposing team give up per game?)\n",
    "_prev5 : stats from previous 5 games of a team matchup\n",
    "\n",
    "'''\n",
    "\n",
    "feature_cols = ['AST%',\n",
    "                'AST%_opp',\n",
    "                'BLKA_per48',\n",
    "                'BLKA_per48_opp',\n",
    "                'DaysRest',\n",
    "                'DaysRest_opp',\n",
    "                'DefRat_z',\n",
    "                'DefRat_z_opp',\n",
    "                'DREB%_opp',\n",
    "                'DREB%',\n",
    "                'FT_PCT',\n",
    "                'FT_PCT_opp',\n",
    "                'Home',\n",
    "                'OffRat_z',\n",
    "                'OffRat_z_opp',\n",
    "                'OREB%_opp',\n",
    "                'OREB%',\n",
    "                'STL%_opp',\n",
    "                'STL%_z',\n",
    "                'TOV%_opp',\n",
    "                'TOV%',\n",
    "                'TOV_forced%_opp',\n",
    "                'TOV_forced%',\n",
    "                'TS%',\n",
    "                'TS%_opp',\n",
    "                'TS%_against',\n",
    "                'TS%_against_opp',\n",
    "                'Win',\n",
    "                'Win_opp',\n",
    "                'eFG%_z',\n",
    "                'eFG%_z_opp',\n",
    "                'eFG%_against',\n",
    "                'eFG%_against_opp',\n",
    "                'roadtrip',\n",
    "                'roadtrip_opp',\n",
    "                'BB%',\n",
    "                'PLUS_MINUS_per48',\n",
    "                'PLUS_MINUS_per48_against',\n",
    "                'PLUS_MINUS_per48_against_opp',\n",
    "                'PLUS_MINUS_per48_opp',\n",
    "                'PTS_per48',\n",
    "                'PTS_per48_against',\n",
    "                'PTS_per48_against_opp',\n",
    "                'PTS_per48_opp',\n",
    "    ]\n",
    "\n",
    "\n",
    "X = df_feat[feature_cols]\n",
    "y = df_feat['WL']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0fb42784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "476/476 [==============================] - 0s 261us/step - loss: 0.6412 - accuracy: 0.6370\n",
      "Epoch 2/50\n",
      "476/476 [==============================] - 0s 251us/step - loss: 0.6334 - accuracy: 0.6443\n",
      "Epoch 3/50\n",
      "476/476 [==============================] - 0s 254us/step - loss: 0.6328 - accuracy: 0.6424\n",
      "Epoch 4/50\n",
      "476/476 [==============================] - 0s 252us/step - loss: 0.6319 - accuracy: 0.6460\n",
      "Epoch 5/50\n",
      "476/476 [==============================] - 0s 253us/step - loss: 0.6326 - accuracy: 0.6454\n",
      "Epoch 6/50\n",
      "476/476 [==============================] - 0s 245us/step - loss: 0.6334 - accuracy: 0.6462\n",
      "Epoch 7/50\n",
      "476/476 [==============================] - 0s 246us/step - loss: 0.6323 - accuracy: 0.6459\n",
      "Epoch 8/50\n",
      "476/476 [==============================] - 0s 256us/step - loss: 0.6331 - accuracy: 0.6481\n",
      "Epoch 9/50\n",
      "476/476 [==============================] - 0s 279us/step - loss: 0.6326 - accuracy: 0.6428\n",
      "Epoch 10/50\n",
      "476/476 [==============================] - 0s 255us/step - loss: 0.6327 - accuracy: 0.6444\n",
      "Epoch 11/50\n",
      "476/476 [==============================] - 0s 244us/step - loss: 0.6319 - accuracy: 0.6410\n",
      "Epoch 12/50\n",
      "476/476 [==============================] - 0s 245us/step - loss: 0.6327 - accuracy: 0.6433\n",
      "Epoch 13/50\n",
      "476/476 [==============================] - 0s 243us/step - loss: 0.6326 - accuracy: 0.6476\n",
      "Epoch 14/50\n",
      "476/476 [==============================] - 0s 242us/step - loss: 0.6325 - accuracy: 0.6450\n",
      "Epoch 15/50\n",
      "476/476 [==============================] - 0s 245us/step - loss: 0.6310 - accuracy: 0.6439\n",
      "Epoch 16/50\n",
      "476/476 [==============================] - 0s 245us/step - loss: 0.6327 - accuracy: 0.6449\n",
      "Epoch 17/50\n",
      "476/476 [==============================] - 0s 244us/step - loss: 0.6328 - accuracy: 0.6437\n",
      "Epoch 18/50\n",
      "476/476 [==============================] - 0s 245us/step - loss: 0.6317 - accuracy: 0.6453\n",
      "Epoch 19/50\n",
      "476/476 [==============================] - 0s 243us/step - loss: 0.6329 - accuracy: 0.6401\n",
      "Epoch 20/50\n",
      "476/476 [==============================] - 0s 264us/step - loss: 0.6331 - accuracy: 0.6461\n",
      "Epoch 21/50\n",
      "476/476 [==============================] - 0s 264us/step - loss: 0.6306 - accuracy: 0.6465\n",
      "Epoch 22/50\n",
      "476/476 [==============================] - 0s 253us/step - loss: 0.6319 - accuracy: 0.6435\n",
      "Epoch 23/50\n",
      "476/476 [==============================] - 0s 278us/step - loss: 0.6322 - accuracy: 0.6453\n",
      "Epoch 24/50\n",
      "476/476 [==============================] - 0s 264us/step - loss: 0.6315 - accuracy: 0.6456\n",
      "Epoch 25/50\n",
      "476/476 [==============================] - 0s 275us/step - loss: 0.6324 - accuracy: 0.6437\n",
      "Epoch 26/50\n",
      "476/476 [==============================] - 0s 263us/step - loss: 0.6320 - accuracy: 0.6437\n",
      "Epoch 27/50\n",
      "476/476 [==============================] - 0s 253us/step - loss: 0.6316 - accuracy: 0.6412\n",
      "Epoch 28/50\n",
      "476/476 [==============================] - 0s 265us/step - loss: 0.6324 - accuracy: 0.6441\n",
      "Epoch 29/50\n",
      "476/476 [==============================] - 0s 278us/step - loss: 0.6320 - accuracy: 0.6467\n",
      "Epoch 30/50\n",
      "476/476 [==============================] - 0s 252us/step - loss: 0.6328 - accuracy: 0.6435\n",
      "Epoch 31/50\n",
      "476/476 [==============================] - 0s 245us/step - loss: 0.6318 - accuracy: 0.6436\n",
      "Epoch 32/50\n",
      "476/476 [==============================] - 0s 246us/step - loss: 0.6314 - accuracy: 0.6437\n",
      "Epoch 33/50\n",
      "476/476 [==============================] - 0s 244us/step - loss: 0.6338 - accuracy: 0.6428\n",
      "Epoch 34/50\n",
      "476/476 [==============================] - 0s 245us/step - loss: 0.6322 - accuracy: 0.6445\n",
      "Epoch 35/50\n",
      "476/476 [==============================] - 0s 252us/step - loss: 0.6333 - accuracy: 0.6423\n",
      "Epoch 36/50\n",
      "476/476 [==============================] - 0s 251us/step - loss: 0.6323 - accuracy: 0.6472\n",
      "Epoch 37/50\n",
      "476/476 [==============================] - 0s 252us/step - loss: 0.6314 - accuracy: 0.6421\n",
      "Epoch 38/50\n",
      "476/476 [==============================] - 0s 247us/step - loss: 0.6322 - accuracy: 0.6441\n",
      "Epoch 39/50\n",
      "476/476 [==============================] - 0s 243us/step - loss: 0.6327 - accuracy: 0.6492\n",
      "Epoch 40/50\n",
      "476/476 [==============================] - 0s 247us/step - loss: 0.6326 - accuracy: 0.6431\n",
      "Epoch 41/50\n",
      "476/476 [==============================] - 0s 250us/step - loss: 0.6324 - accuracy: 0.6455\n",
      "Epoch 42/50\n",
      "476/476 [==============================] - 0s 255us/step - loss: 0.6324 - accuracy: 0.6448\n",
      "Epoch 43/50\n",
      "476/476 [==============================] - 0s 263us/step - loss: 0.6320 - accuracy: 0.6477\n",
      "Epoch 44/50\n",
      "476/476 [==============================] - 0s 247us/step - loss: 0.6324 - accuracy: 0.6474\n",
      "Epoch 45/50\n",
      "476/476 [==============================] - 0s 251us/step - loss: 0.6323 - accuracy: 0.6466\n",
      "Epoch 46/50\n",
      "476/476 [==============================] - 0s 250us/step - loss: 0.6322 - accuracy: 0.6449\n",
      "Epoch 47/50\n",
      "476/476 [==============================] - 0s 247us/step - loss: 0.6338 - accuracy: 0.6443\n",
      "Epoch 48/50\n",
      "476/476 [==============================] - 0s 246us/step - loss: 0.6327 - accuracy: 0.6435\n",
      "Epoch 49/50\n",
      "476/476 [==============================] - 0s 250us/step - loss: 0.6325 - accuracy: 0.6453\n",
      "Epoch 50/50\n",
      "476/476 [==============================] - 0s 253us/step - loss: 0.6313 - accuracy: 0.6467\n",
      "119/119 [==============================] - 0s 286us/step - loss: 0.6374 - accuracy: 0.6449\n",
      "Binary Crossentropy Loss on Test Set: 0.6373957395553589\n",
      "Accuracy on Test Set: 0.6448647379875183\n",
      "119/119 [==============================] - 0s 206us/step\n",
      "True Label: 1 | Predicted Probability: 0.26263428\n",
      "True Label: 1 | Predicted Probability: 0.6247688\n",
      "True Label: 0 | Predicted Probability: 0.28631833\n",
      "True Label: 0 | Predicted Probability: 0.6913834\n",
      "True Label: 1 | Predicted Probability: 0.60663754\n"
     ]
    }
   ],
   "source": [
    "nn_model = Sequential([\n",
    "    Dense(1, input_shape=(len(X_train.columns),), activation='sigmoid')  # Assuming you have 36 features and using sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# compile and train model\n",
    "nn_model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "nn_model.fit(X_train, y_train, epochs=50, verbose=1)\n",
    "loss, nn_accuracy = nn_model.evaluate(X_test, y_test)\n",
    "\n",
    "# predictions\n",
    "nn_prob = nn_model.predict(X_test)\n",
    "nn_pred = np.round(nn_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b10366",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "75d204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.6448647228789073\n",
      "Logistic Regression Accuracy: 0.6495928552666141\n",
      "SVM Accuracy: 0.6472287890727607\n"
     ]
    }
   ],
   "source": [
    "# Combine predictions using majority voting\n",
    "voting_predictions = np.round((nn_pred.T + logit_pred + svm_pred) / 3)[0]\n",
    "\n",
    "nn_wt = nn_accuracy / (nn_accuracy + logit_accuracy + svm_accuracy)\n",
    "logit_wt = logit_accuracy / (nn_accuracy + logit_accuracy + svm_accuracy)\n",
    "svm_wt = svm_accuracy / (nn_accuracy + logit_accuracy + svm_accuracy)\n",
    "\n",
    "# Combine predictions using weighted voting based on probabilities\n",
    "weighted_voting_predictions = np.round((nn_wt * nn_prob.T +\n",
    "                                        logit_wt * logit_prob +\n",
    "                                        svm_wt * svm_prob))[0]\n",
    "\n",
    "# Evaluate individual models\n",
    "print(\"Neural Network Accuracy:\", accuracy_score(y_test, nn_pred))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logit_pred))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "41d2311b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Accuracy: 0.6474914630943\n",
      "Weighted Voting Accuracy: 0.6477541371158393\n"
     ]
    }
   ],
   "source": [
    "# Evaluate ensemble methods\n",
    "print(\"Voting Accuracy:\", accuracy_score(y_test, voting_predictions))\n",
    "print(\"Weighted Voting Accuracy:\", accuracy_score(y_test, weighted_voting_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
